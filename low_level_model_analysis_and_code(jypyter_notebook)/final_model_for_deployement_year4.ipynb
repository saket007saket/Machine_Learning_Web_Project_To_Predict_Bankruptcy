{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,1,2,5,6,7,9,10,13,14,15,16,17,21,23,24,25,28,33,34,35,37,47,49,50,56,58) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\sak\\Documents\\current_hackathon\\bank_ruptcy\\Bankruptcy dataset\\4year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### above feature set i have gone through some feature engineering steps \n",
    "###### missing imputation------>gaussian transformation ----->decision tree descritisation------>scaling --->feature selection \n",
    "[['Attr5','Attr9','Attr15','Attr21','Attr24','Attr27','Attr34','Attr35','Attr40','Attr46','Attr55','Attr58','class']] \n",
    "\n",
    "###### but important analysis i found that feature set using these above feature engineering steps giving best result on original data aftter imputation only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_4=data[['Attr5','Attr9','Attr15','Attr21','Attr24','Attr27','Attr34','Attr35','Attr40','Attr46','Attr55','Attr58','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=year_4.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#replacing each ? to NAN\n",
    "for i in k1:\n",
    "    year_4[i] = year_4[i].replace('?' , np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting object data into numericals(float64)\n",
    "year_4=year_4.apply(lambda col:pd.to_numeric(col,errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr15</th>\n",
       "      <th>Attr21</th>\n",
       "      <th>Attr24</th>\n",
       "      <th>Attr27</th>\n",
       "      <th>Attr34</th>\n",
       "      <th>Attr35</th>\n",
       "      <th>Attr40</th>\n",
       "      <th>Attr46</th>\n",
       "      <th>Attr55</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710.6700</td>\n",
       "      <td>0.61457</td>\n",
       "      <td>518.55</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.045700</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>5.867000</td>\n",
       "      <td>7.01250</td>\n",
       "      <td>679.47</td>\n",
       "      <td>0.70637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.5030</td>\n",
       "      <td>2.49970</td>\n",
       "      <td>122.93</td>\n",
       "      <td>0.65534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7290.8000</td>\n",
       "      <td>15.548000</td>\n",
       "      <td>0.371790</td>\n",
       "      <td>2.045900</td>\n",
       "      <td>5.34640</td>\n",
       "      <td>605.75</td>\n",
       "      <td>0.85001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>432.4800</td>\n",
       "      <td>0.76021</td>\n",
       "      <td>321.01</td>\n",
       "      <td>1.12090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1747.7000</td>\n",
       "      <td>3.607000</td>\n",
       "      <td>0.151850</td>\n",
       "      <td>3.134600</td>\n",
       "      <td>5.22480</td>\n",
       "      <td>776.85</td>\n",
       "      <td>0.85872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213.6700</td>\n",
       "      <td>1.70250</td>\n",
       "      <td>108.70</td>\n",
       "      <td>0.73416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.079000</td>\n",
       "      <td>0.332670</td>\n",
       "      <td>5.482400</td>\n",
       "      <td>8.04050</td>\n",
       "      <td>153.55</td>\n",
       "      <td>0.80466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.8090</td>\n",
       "      <td>1.13950</td>\n",
       "      <td>467.39</td>\n",
       "      <td>0.99457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40348.0000</td>\n",
       "      <td>11.733000</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>3.153000</td>\n",
       "      <td>5.27100</td>\n",
       "      <td>623.05</td>\n",
       "      <td>0.95994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9534</th>\n",
       "      <td>-39.0640</td>\n",
       "      <td>0.97093</td>\n",
       "      <td>2892.60</td>\n",
       "      <td>0.97345</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052162</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.73857</td>\n",
       "      <td>8772.00</td>\n",
       "      <td>1.02990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9535</th>\n",
       "      <td>-20.9230</td>\n",
       "      <td>1.00730</td>\n",
       "      <td>4654.80</td>\n",
       "      <td>0.76438</td>\n",
       "      <td>-0.027610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.115010</td>\n",
       "      <td>0.47808</td>\n",
       "      <td>-564.42</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9536</th>\n",
       "      <td>-1.0692</td>\n",
       "      <td>0.80307</td>\n",
       "      <td>-1267.00</td>\n",
       "      <td>0.38471</td>\n",
       "      <td>-0.240360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.379840</td>\n",
       "      <td>-0.238190</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.98745</td>\n",
       "      <td>7371.80</td>\n",
       "      <td>1.24520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>-214.2400</td>\n",
       "      <td>0.98145</td>\n",
       "      <td>2635.80</td>\n",
       "      <td>0.95615</td>\n",
       "      <td>-0.018774</td>\n",
       "      <td>3.0716</td>\n",
       "      <td>1.239600</td>\n",
       "      <td>0.090025</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.39113</td>\n",
       "      <td>-4346.00</td>\n",
       "      <td>0.68127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9538</th>\n",
       "      <td>-24.2820</td>\n",
       "      <td>1.00140</td>\n",
       "      <td>3027.00</td>\n",
       "      <td>0.97685</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.013821</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.75791</td>\n",
       "      <td>1542.00</td>\n",
       "      <td>0.99861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9539 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Attr5    Attr9   Attr15   Attr21    Attr24      Attr27     Attr34  \\\n",
       "0     710.6700  0.61457   518.55  0.82983       NaN         NaN   3.045700   \n",
       "1      93.5030  2.49970   122.93  0.65534       NaN   7290.8000  15.548000   \n",
       "2     432.4800  0.76021   321.01  1.12090       NaN   1747.7000   3.607000   \n",
       "3     213.6700  1.70250   108.70  0.73416       NaN         NaN  12.079000   \n",
       "4      88.8090  1.13950   467.39  0.99457       NaN  40348.0000  11.733000   \n",
       "...        ...      ...      ...      ...       ...         ...        ...   \n",
       "9534  -39.0640  0.97093  2892.60  0.97345  0.013002         NaN   0.052162   \n",
       "9535  -20.9230  1.00730  4654.80  0.76438 -0.027610         NaN   0.004404   \n",
       "9536   -1.0692  0.80307 -1267.00  0.38471 -0.240360         NaN  -0.379840   \n",
       "9537 -214.2400  0.98145  2635.80  0.95615 -0.018774      3.0716   1.239600   \n",
       "9538  -24.2820  1.00140  3027.00  0.97685  0.027253         NaN   0.028393   \n",
       "\n",
       "        Attr35    Attr40   Attr46   Attr55   Attr58  class  \n",
       "0     0.006970  5.867000  7.01250   679.47  0.70637      0  \n",
       "1     0.371790  2.045900  5.34640   605.75  0.85001      0  \n",
       "2     0.151850  3.134600  5.22480   776.85  0.85872      0  \n",
       "3     0.332670  5.482400  8.04050   153.55  0.80466      0  \n",
       "4     0.034208  3.153000  5.27100   623.05  0.95994      0  \n",
       "...        ...       ...      ...      ...      ...    ...  \n",
       "9534  0.028662  0.005245  0.73857  8772.00  1.02990      1  \n",
       "9535  0.002675  0.115010  0.47808  -564.42  0.99280      1  \n",
       "9536 -0.238190  0.004595  0.98745  7371.80  1.24520      1  \n",
       "9537  0.090025  0.002242  0.39113 -4346.00  0.68127      1  \n",
       "9538  0.013821  0.003703  0.75791  1542.00  0.99861      1  \n",
       "\n",
       "[9539 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  so here i m building model on entire dataset for , so i m not divinding into train and test dataset , so that i do have ample amount of data to train our model more accurately  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=['Attr5','Attr9','Attr15','Attr21','Attr24','Attr27','Attr34','Attr35','Attr40','Attr46','Attr55','Attr58']\n",
    "target=['class']\n",
    "X=year_4[predictors]\n",
    "y=year_4[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we impute the missing values with SimpleImputer\n",
    "\n",
    "# create an instance of the simple imputer\n",
    "# we indicate that we want to impute with the median\n",
    "mean_imputer = SimpleImputer(strategy='mean',)\n",
    "\n",
    "# we fit and transform the predictors dataframe\n",
    "# the imputer will learn the mean of all variables\n",
    "X_new=mean_imputer.fit_transform(X[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1=y.copy()\n",
    "X_1=pd.DataFrame(X_new, columns=predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### over sampling through SMOTE is performed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_res, y_res = sm.fit_sample(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18048"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:- since , i have not splited my data into train-test dataset so my independent and dependent data are in pandas dataframe so in order to implement in XGBoostingClassifier algo in pickled , model will not take dataframe data as input to predict , so i need to convert X(input data ) into numpy array , i m not converting y into numpy array¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(X_res)\n",
    "type(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X_res)\n",
    "y=np.array(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(X)\n",
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "# Classification metrices\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functionalizing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionalize model fittting\n",
    "\n",
    "def FitModel(X,Y,algo_name,algorithm,gridSearchParams,cv):\n",
    "    np.random.seed(10)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=algorithm,\n",
    "        param_grid=gridSearchParams,\n",
    "        cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    best_params = grid_result.best_params_\n",
    "    pred = grid_result.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "   # metrics =grid_result.gr\n",
    "    print(pred)\n",
    "    pickle.dump(grid_result,open(algo_name,'wb'))\n",
    "   \n",
    "    print('Best Params :',best_params)\n",
    "    print('Classification Report :',classification_report(y_test,pred))\n",
    "    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n",
    "    print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  4.4min finished\n",
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 1]\n",
      "Best Params : {'n_estimators': 1000}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      1802\n",
      "           1       0.96      0.99      0.97      1808\n",
      "\n",
      "    accuracy                           0.97      3610\n",
      "   macro avg       0.97      0.97      0.97      3610\n",
      "weighted avg       0.97      0.97      0.97      3610\n",
      "\n",
      "Accuracy Score : 0.9728531855955679\n",
      "Confusion Matrix : \n",
      " [[1726   76]\n",
      " [  22 1786]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [50, 100, 500, 1000, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X,y,'finalized_model2.pkl',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = pickle.load(open(\"finalized_model2.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(np.array([[-214.2400,0.98145,2635.80,0.95615,-0.018774,3.0716,1.239600,0.090025,0.002242,0.39113,-4346.00,0.68127]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change (prediction):\n",
    "    if prediction==1:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the features of company:-\n",
      "[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365 = -214.2400 \n",
      "sales / total assets = 0.98145\n",
      "(total liabilities * 365) / (gross profit + depreciation) = 2635.80\n",
      "sales (n) / sales (n-1) = 0.95615\n",
      "gross profit (in 3 years) / total assets = -0.018774\n",
      "profit on operating activities / financial expenses = 3.0716\n",
      "operating expenses / total liabilities = 1.239600\n",
      "profit on sales / total assets = .090025\n",
      "(current assets - inventory - receivables) / short-term liabilities = 0.002242\n",
      "(current assets - inventory) / short-term liabilities = 0.39113\n",
      "working capital = -4346.00\n",
      "total costs /total sales = 0.68127\n",
      "\n",
      "\n",
      "\n",
      "will company go for bankruptcy ? yes\n"
     ]
    }
   ],
   "source": [
    "print('some of the features of company:-')\n",
    "print('[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365 = -214.2400 ')\n",
    "print('sales / total assets = 0.98145')\n",
    "print('(total liabilities * 365) / (gross profit + depreciation) = 2635.80')\n",
    "print('sales (n) / sales (n-1) = 0.95615')\n",
    "print('gross profit (in 3 years) / total assets = -0.018774')\n",
    "print('profit on operating activities / financial expenses = 3.0716')\n",
    "print('operating expenses / total liabilities = 1.239600')\n",
    "print('profit on sales / total assets = .090025')\n",
    "print('(current assets - inventory - receivables) / short-term liabilities = 0.002242')\n",
    "print('(current assets - inventory) / short-term liabilities = 0.39113')\n",
    "print('working capital = -4346.00')\n",
    "print('total costs /total sales = 0.68127')\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('will company go for bankruptcy ? {}'.format(change(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
