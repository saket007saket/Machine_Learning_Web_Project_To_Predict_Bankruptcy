{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\sak\\Documents\\current_hackathon\\bank_ruptcy\\Bankruptcy dataset\\5year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### above feature set i have gone through some feature engineering steps\n",
    "###### missing imputation------>gaussian transformation ----->decision tree descritisation------>scaling --->feature selection\n",
    "[['Attr1', 'Attr4', 'Attr21', 'Attr27', 'Attr34', 'Attr35', 'Attr52', 'Attr53', 'Attr58']] i got these features\n",
    "\n",
    "###### but important analysis i found that feature set using these above feature engineering steps giving best result on original data aftter imputation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_5=data[['Attr1', 'Attr4', 'Attr21', 'Attr27', 'Attr34', 'Attr35', 'Attr52', 'Attr53', 'Attr58','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=year_5.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#replacing each ? to NAN\n",
    "for i in k1:\n",
    "    year_5[i] = year_5[i].replace('?' , np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting object data into numericals(float64)\n",
    "year_5=year_5.apply(lambda col:pd.to_numeric(col,errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr21</th>\n",
       "      <th>Attr27</th>\n",
       "      <th>Attr34</th>\n",
       "      <th>Attr35</th>\n",
       "      <th>Attr52</th>\n",
       "      <th>Attr53</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014572</td>\n",
       "      <td>1.77480</td>\n",
       "      <td>1.24440</td>\n",
       "      <td>0.17111</td>\n",
       "      <td>0.12651</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.135250</td>\n",
       "      <td>1.18800</td>\n",
       "      <td>0.98906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118140</td>\n",
       "      <td>10.35600</td>\n",
       "      <td>1.13070</td>\n",
       "      <td>1.32100</td>\n",
       "      <td>1.56470</td>\n",
       "      <td>0.106810</td>\n",
       "      <td>0.084429</td>\n",
       "      <td>3.05640</td>\n",
       "      <td>0.87597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.183090</td>\n",
       "      <td>1.75290</td>\n",
       "      <td>1.23560</td>\n",
       "      <td>16.71700</td>\n",
       "      <td>1.66960</td>\n",
       "      <td>0.644980</td>\n",
       "      <td>0.262610</td>\n",
       "      <td>0.85140</td>\n",
       "      <td>0.52907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046751</td>\n",
       "      <td>7.57930</td>\n",
       "      <td>0.79301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.67340</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>2.44760</td>\n",
       "      <td>0.84173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035999</td>\n",
       "      <td>1.55860</td>\n",
       "      <td>1.32360</td>\n",
       "      <td>0.88616</td>\n",
       "      <td>0.24767</td>\n",
       "      <td>0.084147</td>\n",
       "      <td>0.297850</td>\n",
       "      <td>1.07620</td>\n",
       "      <td>0.90850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>0.012898</td>\n",
       "      <td>1.17220</td>\n",
       "      <td>1.03300</td>\n",
       "      <td>1.46370</td>\n",
       "      <td>2.36440</td>\n",
       "      <td>0.033819</td>\n",
       "      <td>0.135140</td>\n",
       "      <td>0.39944</td>\n",
       "      <td>1.01220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>-0.578050</td>\n",
       "      <td>0.16576</td>\n",
       "      <td>0.64770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.55316</td>\n",
       "      <td>-0.534920</td>\n",
       "      <td>0.209120</td>\n",
       "      <td>-0.46385</td>\n",
       "      <td>1.06410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>-0.179050</td>\n",
       "      <td>0.74554</td>\n",
       "      <td>0.83104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14077</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.669130</td>\n",
       "      <td>-1.70670</td>\n",
       "      <td>0.85112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>-0.108860</td>\n",
       "      <td>1.08780</td>\n",
       "      <td>1.12100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.13435</td>\n",
       "      <td>-0.099950</td>\n",
       "      <td>0.192470</td>\n",
       "      <td>0.11530</td>\n",
       "      <td>1.18320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>-0.105370</td>\n",
       "      <td>0.91478</td>\n",
       "      <td>0.71351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.15467</td>\n",
       "      <td>-0.082947</td>\n",
       "      <td>0.356320</td>\n",
       "      <td>0.90779</td>\n",
       "      <td>1.05220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Attr1     Attr4   Attr21    Attr27   Attr34    Attr35    Attr52  \\\n",
       "0     0.014572   1.77480  1.24440   0.17111  0.12651  0.034401  0.135250   \n",
       "1     0.118140  10.35600  1.13070   1.32100  1.56470  0.106810  0.084429   \n",
       "2     0.183090   1.75290  1.23560  16.71700  1.66960  0.644980  0.262610   \n",
       "3     0.046751   7.57930  0.79301       NaN  8.67340  0.003033  0.103200   \n",
       "4     0.035999   1.55860  1.32360   0.88616  0.24767  0.084147  0.297850   \n",
       "...        ...       ...      ...       ...      ...       ...       ...   \n",
       "5422  0.012898   1.17220  1.03300   1.46370  2.36440  0.033819  0.135140   \n",
       "5423 -0.578050   0.16576  0.64770       NaN -0.55316 -0.534920  0.209120   \n",
       "5424 -0.179050   0.74554  0.83104       NaN  0.14077  0.176700  0.669130   \n",
       "5425 -0.108860   1.08780  1.12100       NaN -0.13435 -0.099950  0.192470   \n",
       "5426 -0.105370   0.91478  0.71351       NaN -0.15467 -0.082947  0.356320   \n",
       "\n",
       "       Attr53   Attr58  class  \n",
       "0     1.18800  0.98906      0  \n",
       "1     3.05640  0.87597      0  \n",
       "2     0.85140  0.52907      0  \n",
       "3     2.44760  0.84173      0  \n",
       "4     1.07620  0.90850      0  \n",
       "...       ...      ...    ...  \n",
       "5422  0.39944  1.01220      1  \n",
       "5423 -0.46385  1.06410      1  \n",
       "5424 -1.70670  0.85112      1  \n",
       "5425  0.11530  1.18320      1  \n",
       "5426  0.90779  1.05220      1  \n",
       "\n",
       "[5427 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  so here i m building model on entire dataset for , so i m not divinding into train and test dataset , so that i do have ample amount of data to train our model more accurately  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=['Attr1', 'Attr4', 'Attr21', 'Attr27', 'Attr34', 'Attr35', 'Attr52', 'Attr53', 'Attr58']\n",
    "target=['class']\n",
    "X=year_5[predictors]\n",
    "y=year_5[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we impute the missing values with SimpleImputer\n",
    "\n",
    "# create an instance of the simple imputer\n",
    "# we indicate that we want to impute with the median\n",
    "mean_imputer = SimpleImputer(strategy='mean',)\n",
    "\n",
    "# we fit and transform the predictors dataframe\n",
    "# the imputer will learn the mean of all variables\n",
    "X_new=mean_imputer.fit_transform(X[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1=y.copy()\n",
    "X_1=pd.DataFrame(X_new, columns=predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### over sampling through SMOTE is performed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_res, y_res = sm.fit_sample(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10034"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10034"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:- since , i have not splited my data into train-test dataset so my independent and dependent data are in pandas dataframe so in order to implement in XGBoostingClassifier algo in pickled , model will not take dataframe data as input to predict , so i need to convert X(input data ) into numpy array , i m not converting y into numpy arrayÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(X_res)\n",
    "type(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X_res)\n",
    "y=np.array(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(X)\n",
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "# Classification metrices\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functionalizing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionalize model fittting\n",
    "\n",
    "def FitModel(X,Y,algo_name,algorithm,gridSearchParams,cv):\n",
    "    np.random.seed(10)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=algorithm,\n",
    "        param_grid=gridSearchParams,\n",
    "        cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    best_params = grid_result.best_params_\n",
    "    pred = grid_result.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "   # metrics =grid_result.gr\n",
    "    print(pred)\n",
    "    pickle.dump(grid_result,open(algo_name,'wb'))\n",
    "   \n",
    "    print('Best Params :',best_params)\n",
    "    print('Classification Report :',classification_report(y_test,pred))\n",
    "    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n",
    "    print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  1.6min finished\n",
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 1 1]\n",
      "Best Params : {'n_estimators': 1000}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1028\n",
      "           1       0.95      0.97      0.96       979\n",
      "\n",
      "    accuracy                           0.96      2007\n",
      "   macro avg       0.96      0.96      0.96      2007\n",
      "weighted avg       0.96      0.96      0.96      2007\n",
      "\n",
      "Accuracy Score : 0.9611360239162929\n",
      "Confusion Matrix : \n",
      " [[977  51]\n",
      " [ 27 952]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [50, 100, 500, 1000, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X,y,'finalized_model1.pkl',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = pickle.load(open(\"finalized_model1.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(np.array([[0.035999,1.55860,1.32360,0.88616,0.24767,0.084147,0.297850,1.07620,0.90850]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change (prediction):\n",
    "    if prediction==1:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the features of company:-\n",
      "net profit / total assets = 0.035999\n",
      "current assets / short-term liabilities = 1.55860 \n",
      "sales (n) / sales (n-1) = 1.32360\n",
      "profit on operating activities / financial expenses = 0.88616\n",
      "operating expenses / total liabilities = 0.24767\n",
      "profit on sales / total assets = 0.084147\n",
      "(short-term liabilities * 365) / cost of products sold) = 0.297850\n",
      "equity / fixed assets = 1.07620\n",
      "total costs /total sales = 0.90850\n",
      "\n",
      "\n",
      "\n",
      "will company go for bankruptcy ? No\n"
     ]
    }
   ],
   "source": [
    "print('some of the features of company:-')\n",
    "print('net profit / total assets = 0.035999')\n",
    "print('current assets / short-term liabilities = 1.55860 ')\n",
    "print('sales (n) / sales (n-1) = 1.32360')\n",
    "print('profit on operating activities / financial expenses = 0.88616')\n",
    "print('operating expenses / total liabilities = 0.24767')\n",
    "print('profit on sales / total assets = 0.084147')\n",
    "print('(short-term liabilities * 365) / cost of products sold) = 0.297850')\n",
    "print('equity / fixed assets = 1.07620')\n",
    "print('total costs /total sales = 0.90850')\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('will company go for bankruptcy ? {}'.format(change(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
