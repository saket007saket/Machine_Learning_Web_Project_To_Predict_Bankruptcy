{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\sak\\Documents\\current_hackathon\\bank_ruptcy\\Bankruptcy dataset\\1year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### above feature set i have gone through some feature engineering steps\n",
    "###### missing imputation------>gaussian transformation ----->decision tree descritisation------>scaling --->feature selection\n",
    "[['Attr5', 'Attr11', 'Attr21', 'Attr22', 'Attr24', 'Attr27', 'Attr33', 'Attr40', 'Attr46', 'Attr55']] i got these features\n",
    "\n",
    "###### but important analysis i found that feature set using these above feature engineering steps giving best result on original data aftter imputation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_1=data[['Attr5', 'Attr11', 'Attr21', 'Attr22', 'Attr24', 'Attr27', 'Attr33', 'Attr40', 'Attr46', 'Attr55','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=year_1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#replacing each ? to NAN\n",
    "for i in k1:\n",
    "    year_1[i] = year_1[i].replace('?' , np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting object data into numericals(float64)\n",
    "year_1=year_1.apply(lambda col:pd.to_numeric(col,errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr11</th>\n",
       "      <th>Attr21</th>\n",
       "      <th>Attr22</th>\n",
       "      <th>Attr24</th>\n",
       "      <th>Attr27</th>\n",
       "      <th>Attr33</th>\n",
       "      <th>Attr40</th>\n",
       "      <th>Attr46</th>\n",
       "      <th>Attr55</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.3510</td>\n",
       "      <td>0.249760</td>\n",
       "      <td>1.2479</td>\n",
       "      <td>0.214020</td>\n",
       "      <td>0.477060</td>\n",
       "      <td>1.45820</td>\n",
       "      <td>3.8772</td>\n",
       "      <td>0.662950</td>\n",
       "      <td>1.522500</td>\n",
       "      <td>348690.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.7860</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>1.4293</td>\n",
       "      <td>0.248060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.44400</td>\n",
       "      <td>2.9876</td>\n",
       "      <td>0.086422</td>\n",
       "      <td>1.125200</td>\n",
       "      <td>2304.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.1523</td>\n",
       "      <td>0.312580</td>\n",
       "      <td>1.4283</td>\n",
       "      <td>0.302600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.01100</td>\n",
       "      <td>2.0630</td>\n",
       "      <td>0.322020</td>\n",
       "      <td>1.010100</td>\n",
       "      <td>6332.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.9520</td>\n",
       "      <td>0.092704</td>\n",
       "      <td>1.5069</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>0.171930</td>\n",
       "      <td>0.94076</td>\n",
       "      <td>3.9948</td>\n",
       "      <td>0.401390</td>\n",
       "      <td>1.569600</td>\n",
       "      <td>20545.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.3128</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198320</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>1.41380</td>\n",
       "      <td>2.4823</td>\n",
       "      <td>0.293040</td>\n",
       "      <td>0.957870</td>\n",
       "      <td>3186.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7007</th>\n",
       "      <td>221.0100</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>1.0877</td>\n",
       "      <td>0.046483</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.3098</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>4.636700</td>\n",
       "      <td>5775.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7008</th>\n",
       "      <td>-44.4670</td>\n",
       "      <td>0.033243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.143840</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>-4.47370</td>\n",
       "      <td>3.0876</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.386740</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>-7.2952</td>\n",
       "      <td>-0.067633</td>\n",
       "      <td>1.0377</td>\n",
       "      <td>-0.076312</td>\n",
       "      <td>-0.038146</td>\n",
       "      <td>-3.35570</td>\n",
       "      <td>14.5880</td>\n",
       "      <td>0.036787</td>\n",
       "      <td>0.234050</td>\n",
       "      <td>-396.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>-88.3820</td>\n",
       "      <td>0.215510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189190</td>\n",
       "      <td>0.138090</td>\n",
       "      <td>2.44380</td>\n",
       "      <td>2.9623</td>\n",
       "      <td>0.041756</td>\n",
       "      <td>0.054665</td>\n",
       "      <td>-217.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>-43.1910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128390</td>\n",
       "      <td>0.128380</td>\n",
       "      <td>3170.00000</td>\n",
       "      <td>2.9910</td>\n",
       "      <td>0.025770</td>\n",
       "      <td>0.363710</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7012 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Attr5    Attr11  Attr21    Attr22    Attr24      Attr27   Attr33  \\\n",
       "0      32.3510  0.249760  1.2479  0.214020  0.477060     1.45820   3.8772   \n",
       "1      14.7860  0.261140  1.4293  0.248060       NaN    88.44400   2.9876   \n",
       "2      -1.1523  0.312580  1.4283  0.302600       NaN    86.01100   2.0630   \n",
       "3      51.9520  0.092704  1.5069  0.115500  0.171930     0.94076   3.9948   \n",
       "4      -7.3128  0.187320     NaN  0.198320  0.187320     1.41380   2.4823   \n",
       "...        ...       ...     ...       ...       ...         ...      ...   \n",
       "7007  221.0100  0.045892  1.0877  0.046483  0.045892         NaN   6.3098   \n",
       "7008  -44.4670  0.033243     NaN -0.143840  0.001091    -4.47370   3.0876   \n",
       "7009   -7.2952 -0.067633  1.0377 -0.076312 -0.038146    -3.35570  14.5880   \n",
       "7010  -88.3820  0.215510     NaN  0.189190  0.138090     2.44380   2.9623   \n",
       "7011  -43.1910       NaN     NaN  0.128390  0.128380  3170.00000   2.9910   \n",
       "\n",
       "        Attr40    Attr46     Attr55  class  \n",
       "0     0.662950  1.522500  348690.00      0  \n",
       "1     0.086422  1.125200    2304.60      0  \n",
       "2     0.322020  1.010100    6332.70      0  \n",
       "3     0.401390  1.569600   20545.00      0  \n",
       "4     0.293040  0.957870    3186.60      0  \n",
       "...        ...       ...        ...    ...  \n",
       "7007  0.009419  4.636700    5775.70      1  \n",
       "7008  0.013751  0.386740      14.00      1  \n",
       "7009  0.036787  0.234050    -396.00      1  \n",
       "7010  0.041756  0.054665    -217.42      1  \n",
       "7011  0.025770  0.363710       2.00      1  \n",
       "\n",
       "[7012 rows x 11 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  so here i m building model on entire dataset for , so i m not divinding into train and test dataset , so that i do have ample amount of data to train our model more accurately  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=['Attr5', 'Attr11', 'Attr21', 'Attr22', 'Attr24', 'Attr27', 'Attr33', 'Attr40', 'Attr46', 'Attr55']\n",
    "target=['class']\n",
    "X=year_1[predictors]\n",
    "y=year_1[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we impute the missing values with SimpleImputer\n",
    "\n",
    "# create an instance of the simple imputer\n",
    "# we indicate that we want to impute with the median\n",
    "mean_imputer = SimpleImputer(strategy='mean',)\n",
    "\n",
    "# we fit and transform the predictors dataframe\n",
    "# the imputer will learn the mean of all variables\n",
    "X_new=mean_imputer.fit_transform(X[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1=y.copy()\n",
    "X_1=pd.DataFrame(X_new, columns=predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### over sampling through SMOTE is performed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_res, y_res = sm.fit_sample(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13512"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13512"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:- since , i have not splited my data into train-test dataset so my independent and dependent data are in pandas dataframe so in order to implement in XGBoostingClassifier algo in pickled , model will not take dataframe data as input to predict , so i need to convert X(input data ) into numpy array , i m not converting y into numpy array¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(X_res)\n",
    "type(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X_res)\n",
    "y=np.array(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(X)\n",
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "# Classification metrices\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functionalizing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionalize model fittting\n",
    "\n",
    "def FitModel(X,Y,algo_name,algorithm,gridSearchParams,cv):\n",
    "    np.random.seed(10)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=algorithm,\n",
    "        param_grid=gridSearchParams,\n",
    "        cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    best_params = grid_result.best_params_\n",
    "    pred = grid_result.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "   # metrics =grid_result.gr\n",
    "    print(pred)\n",
    "    pickle.dump(grid_result,open(algo_name,'wb'))\n",
    "   \n",
    "    print('Best Params :',best_params)\n",
    "    print('Classification Report :',classification_report(y_test,pred))\n",
    "    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n",
    "    print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  2.2min finished\n",
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 0]\n",
      "Best Params : {'n_estimators': 500}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1361\n",
      "           1       0.97      0.99      0.98      1342\n",
      "\n",
      "    accuracy                           0.98      2703\n",
      "   macro avg       0.98      0.98      0.98      2703\n",
      "weighted avg       0.98      0.98      0.98      2703\n",
      "\n",
      "Accuracy Score : 0.9800221975582686\n",
      "Confusion Matrix : \n",
      " [[1326   35]\n",
      " [  19 1323]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [50, 100, 500, 1000, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X,y,'finalized_model5.pkl',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = pickle.load(open(\"finalized_model5.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(np.array([[32.3510,0.249760,1.2479,0.214020,0.477060,1.45820,3.8772,0.662950,1.522500,348690.00]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change (prediction):\n",
    "    if prediction==1:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the features of company:-\n",
      "[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365 = 32.3510\n",
      "(gross profit + extraordinary items + financial expenses) / total assets = 0.249760\n",
      "sales (n) / sales (n-1) = 1.2479\n",
      "profit on operating activities / total assets = 0.214020\n",
      "gross profit (in 3 years) / total assets = 0.477060\n",
      "profit on operating activities / financial expenses = 1.45820\n",
      "operating expenses / short-term liabilities = 3.8772\n",
      "(current assets - inventory - receivables) / short-term liabilities = 0.662950\n",
      "(current assets - inventory) / short-term liabilities = 1.522500\n",
      " (sales - cost of products sold) / sales = 348690.00\n",
      "\n",
      "\n",
      "\n",
      "will company go for bankruptcy ? No\n"
     ]
    }
   ],
   "source": [
    "print('some of the features of company:-')\n",
    "print('[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365 = 32.3510')\n",
    "print('(gross profit + extraordinary items + financial expenses) / total assets = 0.249760')\n",
    "print('sales (n) / sales (n-1) = 1.2479')\n",
    "print('profit on operating activities / total assets = 0.214020')\n",
    "print('gross profit (in 3 years) / total assets = 0.477060')\n",
    "print('profit on operating activities / financial expenses = 1.45820')\n",
    "print('operating expenses / short-term liabilities = 3.8772')\n",
    "print('(current assets - inventory - receivables) / short-term liabilities = 0.662950')\n",
    "print('(current assets - inventory) / short-term liabilities = 1.522500')\n",
    "print(' (sales - cost of products sold) / sales = 348690.00')\n",
    "print('\\n\\n')\n",
    "\n",
    "print('will company go for bankruptcy ? {}'.format(change(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
