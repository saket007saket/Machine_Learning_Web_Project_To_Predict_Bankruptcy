{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (14,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\sak\\Documents\\current_hackathon\\bank_ruptcy\\Bankruptcy dataset\\3year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### above feature set i have gone through some feature engineering steps\n",
    "###### missing imputation------>gaussian transformation ----->decision tree descritisation------>scaling --->feature selection\n",
    "[['Attr4','Attr5',  'Attr9', 'Attr13','Attr15', 'Attr21', 'Attr22', 'Attr24',\n",
    "      'Attr27',  'Attr34', 'Attr35', 'Attr40','Attr44'\n",
    "      'Attr46', 'Attr56']] i got these features\n",
    "\n",
    "###### but important analysis i found that feature set using these above feature engineering steps giving best result on original data aftter imputation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_3=data[['Attr4','Attr5',  'Attr9', 'Attr13','Attr15', 'Attr21', 'Attr22', 'Attr24',\n",
    "      'Attr27',  'Attr34', 'Attr35', 'Attr40', 'Attr44', \n",
    "      'Attr46', 'Attr56','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=year_3.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#replacing each ? to NAN\n",
    "for i in k1:\n",
    "    year_3[i] = year_3[i].replace('?' , np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting object data into numericals(float64)\n",
    "year_3=year_3.apply(lambda col:pd.to_numeric(col,errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr13</th>\n",
       "      <th>Attr15</th>\n",
       "      <th>Attr21</th>\n",
       "      <th>Attr22</th>\n",
       "      <th>Attr24</th>\n",
       "      <th>Attr27</th>\n",
       "      <th>Attr34</th>\n",
       "      <th>Attr35</th>\n",
       "      <th>Attr40</th>\n",
       "      <th>Attr44</th>\n",
       "      <th>Attr46</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.34800</td>\n",
       "      <td>-28.9820</td>\n",
       "      <td>1.1961</td>\n",
       "      <td>0.142330</td>\n",
       "      <td>592.24</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>1.97370</td>\n",
       "      <td>0.714530</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.212820</td>\n",
       "      <td>58.109</td>\n",
       "      <td>0.902210</td>\n",
       "      <td>0.163960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.62940</td>\n",
       "      <td>2.5952</td>\n",
       "      <td>1.6018</td>\n",
       "      <td>0.126470</td>\n",
       "      <td>829.46</td>\n",
       "      <td>5.08890</td>\n",
       "      <td>0.175710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.59300</td>\n",
       "      <td>3.383600</td>\n",
       "      <td>0.044076</td>\n",
       "      <td>0.164060</td>\n",
       "      <td>88.801</td>\n",
       "      <td>1.033000</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.15990</td>\n",
       "      <td>84.8740</td>\n",
       "      <td>1.0077</td>\n",
       "      <td>0.030966</td>\n",
       "      <td>2094.10</td>\n",
       "      <td>0.67451</td>\n",
       "      <td>0.040610</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.32153</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.040610</td>\n",
       "      <td>0.844690</td>\n",
       "      <td>96.251</td>\n",
       "      <td>2.329000</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.78330</td>\n",
       "      <td>-10.1050</td>\n",
       "      <td>1.0509</td>\n",
       "      <td>0.036812</td>\n",
       "      <td>3299.40</td>\n",
       "      <td>0.62795</td>\n",
       "      <td>0.055446</td>\n",
       "      <td>0.569440</td>\n",
       "      <td>0.44844</td>\n",
       "      <td>0.128240</td>\n",
       "      <td>0.055446</td>\n",
       "      <td>0.178260</td>\n",
       "      <td>72.237</td>\n",
       "      <td>0.909540</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.92790</td>\n",
       "      <td>-58.2740</td>\n",
       "      <td>1.3393</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>602.31</td>\n",
       "      <td>1.20390</td>\n",
       "      <td>0.234930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.94700</td>\n",
       "      <td>2.657400</td>\n",
       "      <td>0.236350</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>51.585</td>\n",
       "      <td>0.526850</td>\n",
       "      <td>0.176480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10471</th>\n",
       "      <td>0.65465</td>\n",
       "      <td>-85.8970</td>\n",
       "      <td>1.0324</td>\n",
       "      <td>0.032144</td>\n",
       "      <td>4252.70</td>\n",
       "      <td>0.91143</td>\n",
       "      <td>0.037949</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053657</td>\n",
       "      <td>0.037949</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>52.402</td>\n",
       "      <td>0.394580</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10472</th>\n",
       "      <td>0.51247</td>\n",
       "      <td>-90.5840</td>\n",
       "      <td>1.2994</td>\n",
       "      <td>-0.047410</td>\n",
       "      <td>-3551.30</td>\n",
       "      <td>0.49294</td>\n",
       "      <td>-0.165960</td>\n",
       "      <td>1.313400</td>\n",
       "      <td>-5.71820</td>\n",
       "      <td>2.497900</td>\n",
       "      <td>-0.197220</td>\n",
       "      <td>0.047025</td>\n",
       "      <td>21.329</td>\n",
       "      <td>0.220080</td>\n",
       "      <td>-0.151780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10473</th>\n",
       "      <td>1.22850</td>\n",
       "      <td>-51.8630</td>\n",
       "      <td>3.4895</td>\n",
       "      <td>0.019833</td>\n",
       "      <td>3631.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047285</td>\n",
       "      <td>0.222320</td>\n",
       "      <td>0.73724</td>\n",
       "      <td>5.161000</td>\n",
       "      <td>-0.006105</td>\n",
       "      <td>0.036175</td>\n",
       "      <td>17.472</td>\n",
       "      <td>0.982480</td>\n",
       "      <td>-0.001793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10474</th>\n",
       "      <td>0.34372</td>\n",
       "      <td>-375.1600</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>0.095468</td>\n",
       "      <td>4468.80</td>\n",
       "      <td>1.36960</td>\n",
       "      <td>-0.034479</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027477</td>\n",
       "      <td>-0.034479</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>20.965</td>\n",
       "      <td>0.063689</td>\n",
       "      <td>-0.132500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10475</th>\n",
       "      <td>8.01250</td>\n",
       "      <td>42.6760</td>\n",
       "      <td>6.8082</td>\n",
       "      <td>-0.014442</td>\n",
       "      <td>-463.30</td>\n",
       "      <td>1.98050</td>\n",
       "      <td>-0.098326</td>\n",
       "      <td>0.154980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.339000</td>\n",
       "      <td>-0.098326</td>\n",
       "      <td>4.703600</td>\n",
       "      <td>22.140</td>\n",
       "      <td>4.703600</td>\n",
       "      <td>-0.014442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10476 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Attr4     Attr5   Attr9    Attr13   Attr15   Attr21    Attr22  \\\n",
       "0      1.34800  -28.9820  1.1961  0.142330   592.24  0.99690  0.295100   \n",
       "1      1.62940    2.5952  1.6018  0.126470   829.46  5.08890  0.175710   \n",
       "2      3.15990   84.8740  1.0077  0.030966  2094.10  0.67451  0.040610   \n",
       "3      1.78330  -10.1050  1.0509  0.036812  3299.40  0.62795  0.055446   \n",
       "4      1.92790  -58.2740  1.3393  0.187800   602.31  1.20390  0.234930   \n",
       "...        ...       ...     ...       ...      ...      ...       ...   \n",
       "10471  0.65465  -85.8970  1.0324  0.032144  4252.70  0.91143  0.037949   \n",
       "10472  0.51247  -90.5840  1.2994 -0.047410 -3551.30  0.49294 -0.165960   \n",
       "10473  1.22850  -51.8630  3.4895  0.019833  3631.90      NaN  0.047285   \n",
       "10474  0.34372 -375.1600  0.8830  0.095468  4468.80  1.36960 -0.034479   \n",
       "10475  8.01250   42.6760  6.8082 -0.014442  -463.30  1.98050 -0.098326   \n",
       "\n",
       "         Attr24    Attr27     Attr34    Attr35    Attr40  Attr44    Attr46  \\\n",
       "0      0.756410   1.97370   0.714530  0.295100  0.212820  58.109  0.902210   \n",
       "1           NaN  44.59300   3.383600  0.044076  0.164060  88.801  1.033000   \n",
       "2      0.234700   0.32153   0.179600  0.040610  0.844690  96.251  2.329000   \n",
       "3      0.569440   0.44844   0.128240  0.055446  0.178260  72.237  0.909540   \n",
       "4      0.000000  44.94700   2.657400  0.236350  0.013769  51.585  0.526850   \n",
       "...         ...       ...        ...       ...       ...     ...       ...   \n",
       "10471  0.007151       NaN   0.053657  0.037949  0.005115  52.402  0.394580   \n",
       "10472  1.313400  -5.71820   2.497900 -0.197220  0.047025  21.329  0.220080   \n",
       "10473  0.222320   0.73724   5.161000 -0.006105  0.036175  17.472  0.982480   \n",
       "10474  0.026163       NaN  -0.027477 -0.034479  0.014548  20.965  0.063689   \n",
       "10475  0.154980       NaN  55.339000 -0.098326  4.703600  22.140  4.703600   \n",
       "\n",
       "         Attr56  class  \n",
       "0      0.163960      0  \n",
       "1      0.027516      0  \n",
       "2      0.007639      0  \n",
       "3      0.048398      0  \n",
       "4      0.176480      0  \n",
       "...         ...    ...  \n",
       "10471  0.031373      1  \n",
       "10472 -0.151780      1  \n",
       "10473 -0.001793      1  \n",
       "10474 -0.132500      1  \n",
       "10475 -0.014442      1  \n",
       "\n",
       "[10476 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  so here i m building model on entire dataset for , so i m not divinding into train and test dataset , so that i do have ample amount of data to train our model more accurately  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=['Attr4','Attr5',  'Attr9', 'Attr13','Attr15', 'Attr21', 'Attr22', 'Attr24',\n",
    "      'Attr27',  'Attr34', 'Attr35', 'Attr40', 'Attr44', \n",
    "      'Attr46', 'Attr56']\n",
    "target=['class']\n",
    "X=year_3[predictors]\n",
    "y=year_3[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we impute the missing values with SimpleImputer\n",
    "\n",
    "# create an instance of the simple imputer\n",
    "# we indicate that we want to impute with the median\n",
    "mean_imputer = SimpleImputer(strategy='mean',)\n",
    "\n",
    "# we fit and transform the predictors dataframe\n",
    "# the imputer will learn the mean of all variables\n",
    "X_new=mean_imputer.fit_transform(X[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1=y.copy()\n",
    "X_1=pd.DataFrame(X_new, columns=predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### over sampling through SMOTE is performed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_res, y_res = sm.fit_sample(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20016"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20016"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:- since , i have not splited my data into train-test dataset so my independent and dependent data are in pandas dataframe so in order to implement in XGBoostingClassifier algo in pickled , model will not take dataframe data as input to predict , so i need to convert X(input data ) into numpy array , i m not converting y into numpy array¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(X_res)\n",
    "type(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X_res)\n",
    "y=np.array(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(X)\n",
    "#type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "# Classification metrices\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functionalizing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionalize model fittting\n",
    "\n",
    "def FitModel(X,Y,algo_name,algorithm,gridSearchParams,cv):\n",
    "    np.random.seed(10)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=algorithm,\n",
    "        param_grid=gridSearchParams,\n",
    "        cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    best_params = grid_result.best_params_\n",
    "    pred = grid_result.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "   # metrics =grid_result.gr\n",
    "    print(pred)\n",
    "    pickle.dump(grid_result,open(algo_name,'wb'))\n",
    "   \n",
    "    print('Best Params :',best_params)\n",
    "    print('Classification Report :',classification_report(y_test,pred))\n",
    "    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n",
    "    print('Confusion Matrix : \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  5.6min finished\n",
      "C:\\Users\\sak\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 0 0]\n",
      "Best Params : {'n_estimators': 500}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1993\n",
      "           1       0.98      0.99      0.99      2011\n",
      "\n",
      "    accuracy                           0.99      4004\n",
      "   macro avg       0.99      0.99      0.99      4004\n",
      "weighted avg       0.99      0.99      0.99      4004\n",
      "\n",
      "Accuracy Score : 0.9865134865134865\n",
      "Confusion Matrix : \n",
      " [[1950   43]\n",
      " [  11 2000]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [50, 100, 500, 1000, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X,y,'finalized_model3.pkl',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = pickle.load(open(\"finalized_model3.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(np.array([[0.51247,90.5840,1.2994,-0.047410,-3551.30,0.49294,-0.165960,1.313400,-5.71820,2.497900,-0.197220,0.047025,21.329,0.220080,-0.151780]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change (prediction):\n",
    "    if prediction==1:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some of the features of company:-\n",
      "current assets / short-term liabilities = 0.51247\n",
      "[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365 = 90.5840\n",
      "sales / total assets = 1.2994\n",
      "(gross profit + depreciation) / sales = -0.047410\n",
      "(total liabilities * 365) / (gross profit + depreciation) = -3551.30\n",
      "sales (n) / sales (n-1) = 0.49294\n",
      "profit on operating activities / total assets = -0.165960\n",
      "gross profit (in 3 years) / total assets = 1.313400\n",
      "profit on operating activities / financial expenses = -5.71820\n",
      "operating expenses / total liabilities = 2.497900\n",
      "profit on sales / total assets = -0.197220\n",
      "(current assets - inventory - receivables) / short-term liabilities = 0.047025\n",
      "(receivables * 365) / sales = 21.329\n",
      "(current assets - inventory) / short-term liabilities = 0.220080\n",
      "(sales - cost of products sold) / sales = -0.151780\n",
      "\n",
      "\n",
      "\n",
      "will company go for bankruptcy ? yes\n"
     ]
    }
   ],
   "source": [
    "print('some of the features of company:-')\n",
    "print('current assets / short-term liabilities = 0.51247')\n",
    "print('[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365 = 90.5840')\n",
    "print('sales / total assets = 1.2994')\n",
    "print('(gross profit + depreciation) / sales = -0.047410')\n",
    "print('(total liabilities * 365) / (gross profit + depreciation) = -3551.30')\n",
    "print('sales (n) / sales (n-1) = 0.49294')\n",
    "print('profit on operating activities / total assets = -0.165960')\n",
    "print('gross profit (in 3 years) / total assets = 1.313400')\n",
    "print('profit on operating activities / financial expenses = -5.71820')\n",
    "print('operating expenses / total liabilities = 2.497900')\n",
    "print('profit on sales / total assets = -0.197220')\n",
    "print('(current assets - inventory - receivables) / short-term liabilities = 0.047025')\n",
    "print('(receivables * 365) / sales = 21.329')\n",
    "print('(current assets - inventory) / short-term liabilities = 0.220080')\n",
    "print('(sales - cost of products sold) / sales = -0.151780')\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('will company go for bankruptcy ? {}'.format(change(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
